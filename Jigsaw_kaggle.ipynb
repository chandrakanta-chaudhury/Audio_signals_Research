{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jigsaw_kaggle.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN5AXQ9UqLB2UiUHvsu2eoP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chandrakanta-chaudhury/Misc/blob/master/Jigsaw_kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhCEgrFuB81K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY-5xIWSCL9z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "outputId": "dbb55bcc-fa1e-490f-fb56-d0d46f090e00"
      },
      "source": [
        "VERSION = \"1.5\"  #@param [\"1.5\" , \"20200325\", \"nightly\"]\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  3727  100  3727    0     0  22587      0 --:--:-- --:--:-- --:--:-- 22865\n",
            "Updating TPU and VM. This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-1.5 ...\n",
            "Uninstalling torch-1.5.0a0+ab660ae:\n",
            "  Successfully uninstalled torch-1.5.0a0+ab660ae\n",
            "Uninstalling torchvision-0.6.0a0+3c254fb:\n",
            "  Successfully uninstalled torchvision-0.6.0a0+3c254fb\n",
            "Copying gs://tpu-pytorch/wheels/torch-1.5-cp36-cp36m-linux_x86_64.whl...\n",
            "\\ [1 files][ 79.0 MiB/ 79.0 MiB]                                                \n",
            "Operation completed over 1 objects/79.0 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-1.5-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][106.7 MiB/106.7 MiB]                                                \n",
            "Operation completed over 1 objects/106.7 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-1.5-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.5 MiB/  2.5 MiB]                                                \n",
            "Operation completed over 1 objects/2.5 MiB.                                      \n",
            "Processing ./torch-1.5-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5) (1.18.2)\n",
            "Done updating TPU runtime: <Response [200]>\n",
            "\u001b[31mERROR: fastai 1.0.60 requires torchvision, which is not installed.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.5.0a0+ab660ae\n",
            "Requirement already satisfied: torch-xla==1.5 from file:///content/torch_xla-1.5-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (1.5)\n",
            "Processing ./torchvision-1.5-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==1.5) (1.5.0a0+ab660ae)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==1.5) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==1.5) (1.18.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==1.5) (1.12.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==1.5) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.6.0a0+3c254fb\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libomp5 is already the newest version (5.0.1-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz7BpuvvCqC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "from collections import OrderedDict, namedtuple\n",
        "import torch.nn as nn\n",
        "from torch.optim import lr_scheduler\n",
        "import joblib\n",
        "\n",
        "import logging\n",
        "import transformers\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule\n",
        "import sys\n",
        "from sklearn import metrics, model_selection\n",
        "\n",
        "import warnings\n",
        "import torch_xla\n",
        "import torch_xla.debug.metrics as met\n",
        "import torch_xla.distributed.data_parallel as dp\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.utils.utils as xu\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.test.test_utils as test_utils\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jatWlu3C5Sb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "b96c3579-aa88-432e-e7a5-c1fe2df6786b"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.7.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.31 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.31)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpwYSeNmDcRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AverageMeter:\n",
        "    \"\"\"\n",
        "    Computes and stores the average and current value\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as1Pni73DtlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BERTBaseUncased(nn.Module):\n",
        "    def __init__(self, bert_path):\n",
        "        super(BERTBaseUncased, self).__init__()\n",
        "        self.bert_path = bert_path\n",
        "        self.bert = transformers.BertModel.from_pretrained(self.bert_path)\n",
        "        self.bert_drop = nn.Dropout(0.3)\n",
        "        self.out = nn.Linear(768 * 2, 1)\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            ids,\n",
        "            mask,\n",
        "            token_type_ids\n",
        "    ):\n",
        "        o1, o2 = self.bert(\n",
        "            ids,\n",
        "            attention_mask=mask,\n",
        "            token_type_ids=token_type_ids)\n",
        "        \n",
        "        apool = torch.mean(o1, 1)\n",
        "        mpool, _ = torch.max(o1, 1)\n",
        "        cat = torch.cat((apool, mpool), 1)\n",
        "\n",
        "        bo = self.bert_drop(cat)\n",
        "        p2 = self.out(bo)\n",
        "        return p2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42PKYn1pD4yC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BERTDatasetTraining:\n",
        "    def __init__(self, comment_text, targets, tokenizer, max_length):\n",
        "        self.comment_text = comment_text\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comment_text)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        comment_text = str(self.comment_text[item])\n",
        "        comment_text = \" \".join(comment_text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            comment_text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "        )\n",
        "        ids = inputs[\"input_ids\"]\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "        mask = inputs[\"attention_mask\"]\n",
        "        \n",
        "        padding_length = self.max_length - len(ids)\n",
        "        \n",
        "        ids = ids + ([0] * padding_length)\n",
        "        mask = mask + ([0] * padding_length)\n",
        "        token_type_ids = token_type_ids + ([0] * padding_length)\n",
        "        \n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[item], dtype=torch.float)\n",
        "        }\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lHqebAyEAm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _run():\n",
        "    def loss_fn(outputs, targets):\n",
        "        return nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n",
        "\n",
        "    def train_loop_fn(data_loader, model, optimizer, device, scheduler=None):\n",
        "        model.train()\n",
        "        for bi, d in enumerate(data_loader):\n",
        "            ids = d[\"ids\"]\n",
        "            mask = d[\"mask\"]\n",
        "            token_type_ids = d[\"token_type_ids\"]\n",
        "            targets = d[\"targets\"]\n",
        "\n",
        "            ids = ids.to(device, dtype=torch.long)\n",
        "            mask = mask.to(device, dtype=torch.long)\n",
        "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "            targets = targets.to(device, dtype=torch.float)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(\n",
        "                ids=ids,\n",
        "                mask=mask,\n",
        "                token_type_ids=token_type_ids\n",
        "            )\n",
        "\n",
        "            loss = loss_fn(outputs, targets)\n",
        "            if bi % 10 == 0:\n",
        "                xm.master_print(f'bi={bi}, loss={loss}')\n",
        "\n",
        "            loss.backward()\n",
        "            xm.optimizer_step(optimizer)\n",
        "            if scheduler is not None:\n",
        "                scheduler.step()\n",
        "\n",
        "    def eval_loop_fn(data_loader, model, device):\n",
        "        model.eval()\n",
        "        fin_targets = []\n",
        "        fin_outputs = []\n",
        "        for bi, d in enumerate(data_loader):\n",
        "            ids = d[\"ids\"]\n",
        "            mask = d[\"mask\"]\n",
        "            token_type_ids = d[\"token_type_ids\"]\n",
        "            targets = d[\"targets\"]\n",
        "\n",
        "            ids = ids.to(device, dtype=torch.long)\n",
        "            mask = mask.to(device, dtype=torch.long)\n",
        "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "            targets = targets.to(device, dtype=torch.float)\n",
        "\n",
        "            outputs = model(\n",
        "                ids=ids,\n",
        "                mask=mask,\n",
        "                token_type_ids=token_type_ids\n",
        "            )\n",
        "\n",
        "            targets_np = targets.cpu().detach().numpy().tolist()\n",
        "            outputs_np = outputs.cpu().detach().numpy().tolist()\n",
        "            fin_targets.extend(targets_np)\n",
        "            fin_outputs.extend(outputs_np)    \n",
        "\n",
        "        return fin_outputs, fin_targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWkWbLsMEsil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 192\n",
        "TRAIN_BATCH_SIZE = 128\n",
        "EPOCHS = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7qf2CWSFF3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#API  >kaggle competitions download -c jigsaw-multilingual-toxic-comment-classification\n",
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRLJtW2PFfvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9Ijc6F6Fn69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir .kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF_fNP2ZFtga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcczgB7aF3Kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!touch ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9Via8idF8_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "api_token = {\"username\":\"chandrakanta\",\"key\":\"67f5e0fb3722d0bf9d99e91113d710cc\"}\n",
        "\n",
        "import json\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4uSx1RXGnRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "1b83f75d-4f24-472f-cd92-96570071962f"
      },
      "source": [
        "!kaggle competitions download -c jigsaw-multilingual-toxic-comment-classification"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading test.csv.zip to /content\n",
            " 40% 5.00M/12.4M [00:00<00:00, 15.0MB/s]\n",
            "100% 12.4M/12.4M [00:00<00:00, 31.3MB/s]\n",
            "Downloading jigsaw-toxic-comment-train-processed-seqlen128.csv.zip to /content\n",
            " 90% 72.0M/79.6M [00:00<00:00, 138MB/s]\n",
            "100% 79.6M/79.6M [00:00<00:00, 180MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/612k [00:00<?, ?B/s]\n",
            "100% 612k/612k [00:00<00:00, 132MB/s]\n",
            "Downloading jigsaw-toxic-comment-train.csv.zip to /content\n",
            " 80% 30.0M/37.3M [00:00<00:00, 44.2MB/s]\n",
            "100% 37.3M/37.3M [00:00<00:00, 77.0MB/s]\n",
            "Downloading jigsaw-unintended-bias-train.csv.zip to /content\n",
            " 95% 277M/292M [00:02<00:00, 152MB/s]\n",
            "100% 292M/292M [00:02<00:00, 125MB/s]\n",
            "Downloading test-processed-seqlen128.csv.zip to /content\n",
            " 77% 23.0M/29.8M [00:00<00:00, 48.4MB/s]\n",
            "100% 29.8M/29.8M [00:00<00:00, 97.8MB/s]\n",
            "Downloading validation.csv.zip to /content\n",
            "  0% 0.00/1.35M [00:00<?, ?B/s]\n",
            "100% 1.35M/1.35M [00:00<00:00, 92.1MB/s]\n",
            "Downloading jigsaw-unintended-bias-train-processed-seqlen128.csv.zip to /content\n",
            "100% 647M/650M [00:04<00:00, 119MB/s]\n",
            "100% 650M/650M [00:04<00:00, 137MB/s]\n",
            "Downloading validation-processed-seqlen128.csv.zip to /content\n",
            "  0% 0.00/3.44M [00:00<?, ?B/s]\n",
            "100% 3.44M/3.44M [00:00<00:00, 109MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omZYrzskHQwy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4f67cf82-edc3-45ff-9dd5-1dbb83ff9219"
      },
      "source": [
        "!unzip /content/jigsaw-toxic-comment-train.csv.zip"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/jigsaw-toxic-comment-train.csv.zip\n",
            "  inflating: jigsaw-toxic-comment-train.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHj36dhyH3Lo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5f28972e-267b-447b-fb9d-7e83709f3855"
      },
      "source": [
        "!unzip /content/jigsaw-unintended-bias-train.csv.zip"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/jigsaw-unintended-bias-train.csv.zip\n",
            "  inflating: jigsaw-unintended-bias-train.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow7nwn5SE1sl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train1 = pd.read_csv(\"/content/jigsaw-toxic-comment-train.csv\", usecols=[\"comment_text\", \"toxic\"]).fillna(\"none\")\n",
        "df_train2 = pd.read_csv(\"/content/jigsaw-unintended-bias-train.csv\", usecols=[\"comment_text\", \"toxic\"]).fillna(\"none\")\n",
        "df_train_full = pd.concat([df_train1, df_train2], axis=0).reset_index(drop=True)\n",
        "df_train = df_train_full.sample(frac=1).reset_index(drop=True).head(400000)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJNBUe3EIyIr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f2b0e6ae-3636-4adf-8693-0d1cef792796"
      },
      "source": [
        "!unzip /content/validation.csv.zip"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/validation.csv.zip\n",
            "  inflating: validation.csv          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJqrodXrIbau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_valid = pd.read_csv('/content/validation.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utzCyHCTWao0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get it from here BERT pretrained \n",
        "#!wget https://www.kaggle.com/abhishek/bert-base-multilingual-uncased"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayRfYFOPI9Kd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "771bd02b-541f-49af-8748-97ce94e34ee3"
      },
      "source": [
        "tokenizer = transformers.BertTokenizer.from_pretrained(\"/content/bert-base-multilingual-uncased\", do_lower_case=True)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TufRxoFOM5B9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_targets = df_train.toxic.values\n",
        "valid_targets = df_valid.toxic.values\n",
        "\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqAxD-ObNBLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " train_dataset = BERTDatasetTraining(\n",
        "        comment_text=df_train.comment_text.values,\n",
        "        targets=train_targets,\n",
        "        tokenizer=tokenizer,\n",
        "        max_length=MAX_LEN\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTqNitZsNG-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "          train_dataset,\n",
        "          num_replicas=xm.xrt_world_size(),\n",
        "          rank=xm.get_ordinal(),\n",
        "          shuffle=True)\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=TRAIN_BATCH_SIZE,\n",
        "        sampler=train_sampler,\n",
        "        drop_last=True,\n",
        "        num_workers=4\n",
        "    )\n",
        "\n",
        "valid_dataset = BERTDatasetTraining(\n",
        "        comment_text=df_valid.comment_text.values,\n",
        "        targets=valid_targets,\n",
        "        tokenizer=tokenizer,\n",
        "        max_length=MAX_LEN\n",
        "    )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FvmDCwENNZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "          valid_dataset,\n",
        "          num_replicas=xm.xrt_world_size(),\n",
        "          rank=xm.get_ordinal(),\n",
        "          shuffle=False)\n",
        "\n",
        "valid_data_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=64,\n",
        "        sampler=valid_sampler,\n",
        "        drop_last=False,\n",
        "        num_workers=1\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8yzZKqQNZWM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "outputId": "4cde81d3-347d-471f-8a9a-d8550696955f"
      },
      "source": [
        "device = xm.xla_device()\n",
        "model = BERTBaseUncased(bert_path=\"/content/bert-base-multilingual-uncased/\").to(device)\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
        "lr = 3e-5 * xm.xrt_world_size()\n",
        "num_train_steps = int(len(train_dataset) / TRAIN_BATCH_SIZE / xm.xrt_world_size() * EPOCHS)\n",
        "xm.master_print(f'num_train_steps = {num_train_steps}, world_size={xm.xrt_world_size()}')\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=num_train_steps\n",
        "    )"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, pretrained_config_archive_map, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresolved_config_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m             \u001b[0mconfig_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict_from_json_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_config_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-95a0b7e514b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxla_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBERTBaseUncased\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/bert-base-multilingual-uncased/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mparam_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mno_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LayerNorm.bias'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LayerNorm.weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m optimizer_grouped_parameters = [\n",
            "\u001b[0;32m<ipython-input-47-2eda1ee137b9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, bert_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBERTBaseUncased\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_drop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m768\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             )\n\u001b[1;32m    440\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \"\"\"\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, pretrained_config_archive_map, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m                     )\n\u001b[1;32m    268\u001b[0m                 )\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Can't load '/content/bert-base-multilingual-uncased/'. Make sure that:\n\n- '/content/bert-base-multilingual-uncased/' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or '/content/bert-base-multilingual-uncased/' is the correct path to a directory containing a 'config.json' file\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHwqrTT3VlCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "        para_loader = pl.ParallelLoader(train_data_loader, [device])\n",
        "        train_loop_fn(para_loader.per_device_loader(device), model, optimizer, device, scheduler=scheduler)\n",
        "\n",
        "        para_loader = pl.ParallelLoader(valid_data_loader, [device])\n",
        "        o, t = eval_loop_fn(para_loader.per_device_loader(device), model, device)\n",
        "        xm.save(model.state_dict(), \"model.bin\")\n",
        "        auc = metrics.roc_auc_score(np.array(t) >= 0.5, o)\n",
        "        xm.master_print(f'AUC = {auc}')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}